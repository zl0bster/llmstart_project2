#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞—Ç—É—Å–∞ LM Studio.
"""

import requests
import json

def check_lm_studio():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç–∞—Ç—É—Å LM Studio —Å–µ—Ä–≤–µ—Ä–∞."""
    print("=== –ü—Ä–æ–≤–µ—Ä–∫–∞ LM Studio ===")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Å–µ—Ä–≤–µ—Ä–∞
    try:
        response = requests.get('http://localhost:1234/v1/models', timeout=5)
        if response.status_code == 200:
            models = response.json()
            print("‚úÖ LM Studio —Å–µ—Ä–≤–µ—Ä —Ä–∞–±–æ—Ç–∞–µ—Ç")
            print("üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:")
            for model in models.get('data', []):
                print(f"  - {model['id']}")
        else:
            print(f"‚ùå LM Studio —Å–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {response.status_code}")
            return False
    except requests.exceptions.ConnectionError:
        print("‚ùå –ù–µ —É–¥–∞–µ—Ç—Å—è –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ LM Studio")
        print("üí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ LM Studio –∑–∞–ø—É—â–µ–Ω –∏ —Å–µ—Ä–≤–µ—Ä —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ –ø–æ—Ä—Ç—É 1234")
        return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return False
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å
    try:
        print("\n=== –¢–µ—Å—Ç –ø—Ä–æ—Å—Ç–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ ===")
        response = requests.post('http://localhost:1234/v1/chat/completions',
            json={
                'model': 'openai/gpt-oss-20b',
                'messages': [
                    {'role': 'user', 'content': '–ü—Ä–∏–≤–µ—Ç! –û—Ç–≤–µ—Ç—å –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º: "—Ä–∞–±–æ—Ç–∞–µ—Ç"'}
                ],
                'temperature': 0,
                'max_tokens': 10
            },
            timeout=30
        )
        
        if response.status_code == 200:
            data = response.json()
            if 'choices' in data and len(data['choices']) > 0:
                content = data['choices'][0]['message']['content']
                print(f"‚úÖ LM Studio –æ—Ç–≤–µ—á–∞–µ—Ç: {content}")
                return True
            else:
                print("‚ùå LM Studio –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
                return False
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {response.status_code} - {response.text}")
            return False
            
    except requests.exceptions.Timeout:
        print("‚ùå –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ - LM Studio –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç")
        return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞: {e}")
        return False

if __name__ == "__main__":
    if check_lm_studio():
        print("\nüéâ LM Studio –Ω–∞—Å—Ç—Ä–æ–µ–Ω –ø—Ä–∞–≤–∏–ª—å–Ω–æ!")
    else:
        print("\nüîß –¢—Ä–µ–±—É–µ—Ç—Å—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ LM Studio:")
        print("1. –û—Ç–∫—Ä–æ–π—Ç–µ LM Studio")
        print("2. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ –≤–∫–ª–∞–¥–∫—É 'Local Server'")
        print("3. –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å openai/gpt-oss-20b")
        print("4. –ù–∞–∂–º–∏—Ç–µ 'Start Server'")
        print("5. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Å–µ—Ä–≤–µ—Ä —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ –ø–æ—Ä—Ç—É 1234")
