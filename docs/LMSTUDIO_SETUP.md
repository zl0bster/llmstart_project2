# Настройка LM Studio для OTK Assistant

## Обзор

LM Studio позволяет запускать локальные LLM модели на вашем компьютере, что обеспечивает:
- Полную приватность данных
- Отсутствие ограничений по API
- Бесплатное использование
- Быструю работу без интернета

## Установка LM Studio

1. **Скачайте LM Studio** с официального сайта: https://lmstudio.ai/
2. **Установите приложение** согласно инструкциям для вашей ОС
3. **Запустите LM Studio**

## Загрузка модели openai/gpt-oss-20b

1. **Откройте вкладку "Models"** в LM Studio
2. **Найдите модель** `openai/gpt-oss-20b` в поиске
3. **Скачайте модель** (размер ~40GB, потребуется время)
4. **Дождитесь завершения загрузки**

## Настройка сервера

1. **Перейдите на вкладку "Local Server"**
2. **Выберите модель** `openai/gpt-oss-20b` из списка
3. **Настройте параметры**:
   - **Context Length**: 4096 (или больше)
   - **Temperature**: 0.0 (для детерминированных ответов)
   - **Max Tokens**: 2000
4. **Запустите сервер** нажатием кнопки "Start Server"
5. **Убедитесь**, что сервер работает на `http://localhost:1234`

## Настройка .env файла

Создайте файл `.env` на основе `env.example`:

```bash
# Скопируйте пример конфигурации
cp env.example .env
```

Отредактируйте `.env` файл:

```env
# Провайдер для текстового анализа
LLM_PROVIDER=lmstudio

# Текстовая модель
TEXT_MODEL=openai/gpt-oss-20b

# URL локального LM Studio
LMSTUDIO_BASE_URL=http://localhost:1234

# Токен бота (обязательно)
BOT_TOKEN=your_telegram_bot_token_here
```

## Проверка работы

1. **Убедитесь, что LM Studio запущен** и сервер работает
2. **Запустите тест**:
   ```bash
   python tests/test_llm_extraction.py
   ```
3. **Проверьте логи** на наличие сообщений о подключении к LM Studio

## Возможные проблемы

### Сервер недоступен
- Убедитесь, что LM Studio запущен
- Проверьте, что сервер работает на порту 1234
- Попробуйте перезапустить сервер в LM Studio

### Модель не загружена
- Убедитесь, что модель `openai/gpt-oss-20b` скачана
- Проверьте, что модель выбрана в настройках сервера
- Попробуйте перезагрузить модель

### Медленная работа
- Убедитесь, что у вас достаточно RAM (рекомендуется 16GB+)
- Закройте другие ресурсоемкие приложения
- Попробуйте уменьшить Context Length в настройках

### Ошибки парсинга
- Модель может давать неструктурированные ответы
- Проверьте логи для деталей ошибок
- Попробуйте другую модель или настройки

## Альтернативные модели

Если `openai/gpt-oss-20b` не работает, попробуйте:

- `microsoft/DialoGPT-medium`
- `microsoft/DialoGPT-large`
- `facebook/blenderbot-400M-distill`
- `microsoft/DialoGPT-small`

Обновите `TEXT_MODEL` в `.env` файле соответственно.

## Мониторинг

- **LM Studio Dashboard**: показывает использование GPU/CPU
- **Логи приложения**: содержат информацию о запросах к LLM
- **Telegram бот**: покажет ошибки при недоступности сервиса

## Производительность

- **Время ответа**: 2-10 секунд в зависимости от сложности запроса
- **Потребление RAM**: 8-16GB для модели 20B
- **GPU**: рекомендуется для ускорения (CUDA/OpenCL)

## Безопасность

- Все данные обрабатываются локально
- Нет передачи данных в интернет
- Полная приватность ваших отчетов ОТК
